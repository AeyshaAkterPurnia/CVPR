{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnUnIms+FjetLJnx9l9jTg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AeyshaAkterPurnia/CVPR/blob/main/Number-detection/realtime_checkpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_AEyCSnQk2T_"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"mnist_nn.keras\")\n",
        "\n",
        "# ---------------- CAMERA --------------------\n",
        "video = cv2.VideoCapture(0)\n",
        "\n",
        "if not video.isOpened():\n",
        "    print(\"❌ Camera not detected\")\n",
        "    exit()\n",
        "\n",
        "cv2.namedWindow(\"Frame\", cv2.WINDOW_NORMAL)\n",
        "cv2.namedWindow(\"Binary (Thresh)\", cv2.WINDOW_NORMAL)\n",
        "\n",
        "cv2.resizeWindow(\"Frame\", 720, 500)\n",
        "cv2.resizeWindow(\"Binary (Thresh)\", 400, 300)\n",
        "\n",
        "cv2.moveWindow(\"Frame\", 100, 100)\n",
        "cv2.moveWindow(\"Binary (Thresh)\", 900, 100)\n",
        "\n",
        "CONF_THRESHOLD = 0.80\n",
        "\n",
        "# ---------------- MAIN LOOP -----------------\n",
        "while True:\n",
        "    ret, frame = video.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
        "\n",
        "    thresh = cv2.adaptiveThreshold(\n",
        "        gray, 255,\n",
        "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "        cv2.THRESH_BINARY_INV, 11, 2\n",
        "    )\n",
        "\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    contours, _ = cv2.findContours(\n",
        "        thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
        "    )\n",
        "\n",
        "    label = \"Searching...\"\n",
        "    color = (0, 0, 255)\n",
        "\n",
        "    if contours:\n",
        "        cnt = max(contours, key=cv2.contourArea)\n",
        "\n",
        "        if cv2.contourArea(cnt) > 1000:\n",
        "            x, y, w, h = cv2.boundingRect(cnt)\n",
        "\n",
        "            roi = thresh[y:y+h, x:x+w]\n",
        "\n",
        "            size = max(w, h) + 40\n",
        "            square = np.zeros((size, size), dtype=\"uint8\")\n",
        "\n",
        "            dx = (size - w) // 2\n",
        "            dy = (size - h) // 2\n",
        "            square[dy:dy+h, dx:dx+w] = roi\n",
        "\n",
        "            final_img = cv2.resize(square, (28, 28), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "            _, final_img = cv2.threshold(\n",
        "                final_img, 120, 255, cv2.THRESH_BINARY\n",
        "            )\n",
        "\n",
        "            # ✅ CNN INPUT SHAPE\n",
        "            input_data = final_img.reshape(1, 28, 28, 1).astype(\"float32\") / 255.0\n",
        "\n",
        "            prediction = model.predict(input_data, verbose=0)\n",
        "            digit = np.argmax(prediction)\n",
        "            conf = np.max(prediction)\n",
        "\n",
        "            if conf >= CONF_THRESHOLD:\n",
        "                label = f\"ID: {digit} ({conf*100:.1f}%)\"\n",
        "                color = (0, 255, 0)\n",
        "\n",
        "                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
        "                cv2.imshow(\"Binary (Thresh)\", final_img)\n",
        "\n",
        "    cv2.putText(\n",
        "        frame, label, (20, 40),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 2\n",
        "    )\n",
        "\n",
        "    cv2.imshow(\"Frame\", frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == 27:  # ESC key\n",
        "        break\n",
        "\n",
        "# ---------------- CLEANUP ------------------\n",
        "video.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "RZp64xmxlYX0",
        "outputId": "1f6504d9-5fd3-4d96-9542-1f8a49d8d765"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "File not found: filepath=mnist_nn.keras. Please ensure the file is an accessible `.keras` zip file.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2851241528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mnist_nn.keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# ---------------- CAMERA --------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n\u001b[1;32m    199\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0;34mf\"File not found: filepath={filepath}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;34m\"Please ensure the file is an accessible `.keras` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: File not found: filepath=mnist_nn.keras. Please ensure the file is an accessible `.keras` zip file."
          ]
        }
      ]
    }
  ]
}